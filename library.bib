Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@misc{CMUSphinx,
author = {CMUSphinx},
booktitle = {2019},
title = {{Tuning speech recognition accuracy – CMUSphinx Open Source Speech Recognition}},
url = {https://cmusphinx.github.io/ https://cmusphinx.github.io/wiki/ https://cmusphinx.github.io/wiki/tutorialtuning/},
urldate = {2019-05-27}
}
@article{Lamere2003,
abstract = {The Sphinx-4 speech recognition system is the latest addition to Carnegie Mellon University's repository of Sphinx speech recognition systems. It has been jointly designed by Carnegie Mellon University, Sun Microsystems Laboratories and Mitsubishi Electric Research Laboratories. It is differently designed from the earlier Sphinx systems in terms of modularity, flexibility and algorithmic aspects. It uses newer search strategies, is universal in its acceptance of various kinds of grammars and language models, types of acoustic models and feature streams. Algorithmic innovations included in the system design enable it to incorporate multiple information sources in an elegant manner. The system is entirely developed on the Java™ platform and is highly portable, flexible, and easier to use with multithreading. This paper describes the salient features of the Sphinx-4 decoder and includes preliminary performance measures relating to speed and accuracy.},
author = {Lamere, Paul and Kwok, Philip and Gouvea, Evandro and Raj, Bhiksha and Singh, Rita and Walker, William and Warmuth, Manfred and Wolf, Peter},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Lamere et al. - Unknown - The CMU Sphinx-4 Speech Recognition System.pdf:pdf},
isbn = {0-7803-7663-3},
journal = {IEEE Intl. Conf. on Acoustics, Speech and Signal Processing (ICASSP 2003), Hong Kong},
pages = {2--5},
title = {{The CMU SPHINX-4 speech recognition system}},
url = {https://pdfs.semanticscholar.org/5064/c602c3a57f4e6f1e4c8f8fb137384c5d41a7.pdf},
volume = {1},
year = {2003}
}
@techreport{Sanfeliu,
author = {Sanfeliu, Alberto and Ruiz-Shulcloper, Jos{\'{e}}},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Sanfeliu, Ruiz-Shulcloper - Unknown - LNCS 2905 - Progress in Pattern Recognition, Speech and Image Analysis.pdf:pdf},
title = {{LNCS 2905 - Progress in Pattern Recognition, Speech and Image Analysis}}
}
@article{Kepuska2017,
abstract = {The idea of this paper is to design a tool that will be used to test and compare commercial speech recognition systems, such as Microsoft Speech API and Google Speech API, with open-source speech recognition systems such as Sphinx-4. The best way to compare automatic speech recognition systems in different environments is by using some audio recordings that were selected from different sources and calculating the word error rate (WER). Although the WER of the three aforementioned systems were acceptable, it was observed that the Google API is superior.},
author = {K{\"{e}}puska, Veton},
doi = {10.9790/9622-0703022024},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/K{\"{e}}puska - 2017 - Comparing Speech Recognition Systems (Microsoft API, Google API And CMU Sphinx).pdf:pdf},
issn = {22489622},
journal = {International Journal of Engineering Research and Applications},
month = {mar},
number = {03},
pages = {20--24},
publisher = {IOSR Journals},
title = {{Comparing Speech Recognition Systems (Microsoft API, Google API And CMU Sphinx)}},
volume = {07},
year = {2017}
}
@inproceedings{Deleglise2009,
abstract = {This paper describes the new ASR system developed by the LIUM and analyzes the various origins of the significant drop of the word error rate observed in comparison to the previous LIUM ASR system. This study was made on the test data of the latest evaluation campaign of ASR systems on French broadcast news, called ESTER 2 and organized in December 2008. For the same computation time, the new system yields a word error rate about 38{\%} lower than what the previous system (which reached the second position during the ESTER 1 evaluation campaign) did. This paper evaluates the gain provided by various changes to the system: implementation of new search and training algorithms, new training data, vocabulary size, etc. The LIUM ASR system was the best open-source ASR system of the ESTER 2 campaign. Copyright {\textcopyright} 2009 ISCA.},
author = {Del{\'{e}}glise, Paul and Est{\`{e}}ve, Yannick and Meignier, Sylvain and Merlin, Teva},
booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Del{\'{e}}glise et al. - 2009 - Improvements to the LIUM French ASR system based on CMU Sphinx What helps to significantly reduce the word er.pdf:pdf},
issn = {19909772},
keywords = {Acoustic model,Automatic speech recognition system,Evaluation,Language modeling},
pages = {2123--2126},
title = {{Improvements to the LIUM French ASR system based on CMU Sphinx: What helps to significantly reduce the word error rate?}},
year = {2009}
}
@article{Deleglise2005,
abstract = {This paper presents the system used by the LIUM to participate in ESTER, the french broadcast news evaluation campaign. This system is based on the CMU Sphinx 3.3 (fast) decoder. Some tools are presented which have been added on different steps of the Sphinx recognition process: segmentation, acoustic model adaptation, word-lattice rescoring. Several experiments have been conducted on studying the effects of the signal segmentation on the recognition process, on injecting automatically transcribed data into training corpora, or on testing different approaches for acoustic model adaptation. The results are presented in this paper. With very few modiﬁcations and a simple MAP acoustic model estimation, Sphinx3.3 decoder reached a word error rate of 28.2{\%}. The entire system developed by LIUM obtained 23.6{\%} as ofﬁcial word error rate for the ESTER evaluation, and 23.4{\%} as result of an unsubmited system.},
author = {Del{\'{e}}glise, Paul and Esteve, Y and Meignier, Sylvain and Merlin, Teva},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Del{\'{e}}glise et al. - 2005 - The LIUM speech transcription system a CMU Sphinx III-based system for french broadcast news The LIUM speech.pdf:pdf},
journal = {Interspeech},
pages = {3--6},
title = {{The LIUM speech transcription system: a CMU Sphinx III-based system for French broadcast news.}},
url = {https://hal.archives-ouvertes.fr/hal-01434282 http://lium3.univ-lemans.fr/lium{\_}d5/sites/default/files/LIUM{\_}Interspeech05.pdf},
year = {2005}
}
@techreport{Walker2004,
author = {Walker, Willie and Lamere, Paul and Kwok, Philip and Raj, Bhiksha and Singh, Rita and Gouvea, Evandro and Wolf, Peter and Woelfel, Joe},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Walker et al. - 2004 - Sphinx-4 A Flexible Open Source Framework for Speech Recognition.pdf:pdf},
keywords = {HMM,Sun Labs,Sun Microsystems Laboratories,hidden Markov model,speech recognition},
title = {{Sphinx-4: A Flexible Open Source Framework for Speech Recognition}},
url = {http://research.sun.com/techrep/.},
year = {2004}
}
