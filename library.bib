Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Lee2003,
abstract = {A description is given of SPHINX an accurate large-vocabulary$\backslash$nspeaker-independent continuous speech recognition system. The authors$\backslash$nhave made several recent enhancements, including generalized triphone$\backslash$nmodels, word duration modeling, function-phrase modeling, between-word$\backslash$ncoarticulation modeling, and corrective training. On the 997-word$\backslash$nresource management task, SPHINX attained a word accuracy of 96{\%} with a$\backslash$ngrammar (perplexity 60), and 82{\%} without grammar (perplexity 997)},
author = {Lee, K.-F. and Hon, H.-W. and Hwang, M.-Y. and Mahajan, S. and Reddy, R.},
doi = {10.1109/icassp.1989.266459},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Lee et al. - 2003 - The SPHINX speech recognition system.pdf:pdf},
pages = {445--448},
title = {{The SPHINX speech recognition system}},
year = {2003}
}
@misc{flask-socketio,
abstract = {Flask-SocketIO gives Flask applications access to low latency bi-directional communications between the clients and the server. The client-side application can use any of the SocketIO official clients libraries in Javascript, C++, Java and Swift, or any compatible client to establish a permanent connection to the server.},
author = {Grinberg, Miguel},
title = {{Flask-SocketIO}},
url = {https://flask-socketio.readthedocs.io/en/latest/}
}
@inproceedings{Deleglise2009,
abstract = {This paper describes the new ASR system developed by the LIUM and analyzes the various origins of the significant drop of the word error rate observed in comparison to the previous LIUM ASR system. This study was made on the test data of the latest evaluation campaign of ASR systems on French broadcast news, called ESTER 2 and organized in December 2008. For the same computation time, the new system yields a word error rate about 38{\%} lower than what the previous system (which reached the second position during the ESTER 1 evaluation campaign) did. This paper evaluates the gain provided by various changes to the system: implementation of new search and training algorithms, new training data, vocabulary size, etc. The LIUM ASR system was the best open-source ASR system of the ESTER 2 campaign. Copyright {\textcopyright} 2009 ISCA.},
author = {Del{\'{e}}glise, Paul and Est{\`{e}}ve, Yannick and Meignier, Sylvain and Merlin, Teva},
booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Del{\'{e}}glise et al. - 2009 - Improvements to the LIUM French ASR system based on CMU Sphinx What helps to significantly reduce the word er.pdf:pdf},
issn = {19909772},
keywords = {Acoustic model,Automatic speech recognition system,Evaluation,Language modeling},
pages = {2123--2126},
title = {{Improvements to the LIUM French ASR system based on CMU Sphinx: What helps to significantly reduce the word error rate?}},
year = {2009}
}
@article{Lamere2003,
abstract = {The Sphinx-4 speech recognition system is the latest addition to Carnegie Mellon University's repository of Sphinx speech recognition systems. It has been jointly designed by Carnegie Mellon University, Sun Microsystems Laboratories and Mitsubishi Electric Research Laboratories. It is differently designed from the earlier Sphinx systems in terms of modularity, flexibility and algorithmic aspects. It uses newer search strategies, is universal in its acceptance of various kinds of grammars and language models, types of acoustic models and feature streams. Algorithmic innovations included in the system design enable it to incorporate multiple information sources in an elegant manner. The system is entirely developed on the Java™ platform and is highly portable, flexible, and easier to use with multithreading. This paper describes the salient features of the Sphinx-4 decoder and includes preliminary performance measures relating to speed and accuracy.},
author = {Lamere, Paul and Kwok, Philip and Gouvea, Evandro and Raj, Bhiksha and Singh, Rita and Walker, William and Warmuth, Manfred and Wolf, Peter},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Lamere et al. - Unknown - The CMU Sphinx-4 Speech Recognition System.pdf:pdf},
isbn = {0-7803-7663-3},
journal = {IEEE Intl. Conf. on Acoustics, Speech and Signal Processing (ICASSP 2003), Hong Kong},
pages = {2--5},
title = {{The CMU SPHINX-4 speech recognition system}},
url = {https://pdfs.semanticscholar.org/5064/c602c3a57f4e6f1e4c8f8fb137384c5d41a7.pdf},
volume = {1},
year = {2003}
}
@techreport{Walker2004,
author = {Walker, Willie and Lamere, Paul and Kwok, Philip and Raj, Bhiksha and Singh, Rita and Gouvea, Evandro and Wolf, Peter and Woelfel, Joe},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Walker et al. - 2004 - Sphinx-4 A Flexible Open Source Framework for Speech Recognition.pdf:pdf},
keywords = {HMM,Sun Labs,Sun Microsystems Laboratories,hidden Markov model,speech recognition},
title = {{Sphinx-4: A Flexible Open Source Framework for Speech Recognition}},
url = {http://research.sun.com/techrep/.},
year = {2004}
}
@article{Deleglise2005,
abstract = {This paper presents the system used by the LIUM to participate in ESTER, the french broadcast news evaluation campaign. This system is based on the CMU Sphinx 3.3 (fast) decoder. Some tools are presented which have been added on different steps of the Sphinx recognition process: segmentation, acoustic model adaptation, word-lattice rescoring. Several experiments have been conducted on studying the effects of the signal segmentation on the recognition process, on injecting automatically transcribed data into training corpora, or on testing different approaches for acoustic model adaptation. The results are presented in this paper. With very few modiﬁcations and a simple MAP acoustic model estimation, Sphinx3.3 decoder reached a word error rate of 28.2{\%}. The entire system developed by LIUM obtained 23.6{\%} as ofﬁcial word error rate for the ESTER evaluation, and 23.4{\%} as result of an unsubmited system.},
author = {Del{\'{e}}glise, Paul and Esteve, Y and Meignier, Sylvain and Merlin, Teva},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Del{\'{e}}glise et al. - 2005 - The LIUM speech transcription system a CMU Sphinx III-based system for french broadcast news The LIUM speech.pdf:pdf},
journal = {Interspeech},
pages = {3--6},
title = {{The LIUM speech transcription system: a CMU Sphinx III-based system for French broadcast news.}},
url = {https://hal.archives-ouvertes.fr/hal-01434282 http://lium3.univ-lemans.fr/lium{\_}d5/sites/default/files/LIUM{\_}Interspeech05.pdf},
year = {2005}
}
@article{Kepuska2017,
abstract = {The idea of this paper is to design a tool that will be used to test and compare commercial speech recognition systems, such as Microsoft Speech API and Google Speech API, with open-source speech recognition systems such as Sphinx-4. The best way to compare automatic speech recognition systems in different environments is by using some audio recordings that were selected from different sources and calculating the word error rate (WER). Although the WER of the three aforementioned systems were acceptable, it was observed that the Google API is superior.},
author = {K{\"{e}}puska, Veton},
doi = {10.9790/9622-0703022024},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/K{\"{e}}puska - 2017 - Comparing Speech Recognition Systems (Microsoft API, Google API And CMU Sphinx).pdf:pdf},
issn = {22489622},
journal = {International Journal of Engineering Research and Applications},
month = {mar},
number = {03},
pages = {20--24},
publisher = {IOSR Journals},
title = {{Comparing Speech Recognition Systems (Microsoft API, Google API And CMU Sphinx)}},
volume = {07},
year = {2017}
}
@techreport{Sanfeliu,
author = {Sanfeliu, Alberto and Ruiz-Shulcloper, Jos{\'{e}}},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Sanfeliu, Ruiz-Shulcloper - Unknown - LNCS 2905 - Progress in Pattern Recognition, Speech and Image Analysis.pdf:pdf},
title = {{LNCS 2905 - Progress in Pattern Recognition, Speech and Image Analysis}}
}
@misc{CMUSphinx,
author = {CMUSphinx},
booktitle = {2019},
title = {{Tuning speech recognition accuracy – CMUSphinx Open Source Speech Recognition}},
url = {https://cmusphinx.github.io/ https://cmusphinx.github.io/wiki/ https://cmusphinx.github.io/wiki/tutorialtuning/},
urldate = {2019-05-27}
}
@article{Hannemann2017,
abstract = {Grapheme-to-phoneme conversion is the task of finding the pronunciation of a word given its written form. It has important applications in text-to-speech and speech recognition. Joint-sequence models are a simple and theoretically stringent probabilistic framework that is applicable to this problem. This article provides a self-contained and detailed description of this method. We present a novel estimation algorithm and demonstrate high accuracy on a variety of databases. Moreover, we study the impact of the maximum approximation in training and transcription, the interaction of model size parameters, n-best list generation, confidence measures, and phoneme-to-grapheme conversion. Our software implementation of the method proposed in this work is available under an Open Source license. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Hannemann, Mirko and Trmal, Jan and Ondel, Lucas and Kesiraju, Santosh and Burget, Lukas},
doi = {10.1109/ICASSP.2017.7952674},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Hannemann et al. - 2017 - Bayesian joint-sequence models for grapheme-to-phoneme conversion.pdf:pdf},
isbn = {9781509041176},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {Bayesian approach,grapheme-tophoneme conversion,hierarchical Pitman-Yor-Process,joint-sequence models,letter-to-sound,weighted finite state transducers},
pages = {2836--2840},
title = {{Bayesian joint-sequence models for grapheme-to-phoneme conversion}},
volume = {50},
year = {2017}
}
@misc{Robert,
abstract = {Pydub lets you do stuff to audio in a way that isn't stupid.},
author = {Robert, James},
title = {pydub},
url = {https://github.com/jiaaro/pydub},
year = {2011}
}
@article{Stolcke2002,
abstract = {SRILM is a collection of C++ libraries, executable programs, and helper scripts designed to allow both production of and experimentation with statistical language models for speech recognition and other applications. SRILM is freely available for noncommercial purposes. The toolkit supports creation and evaluation of a variety of language model types based on N-gram statistics, as well as several related tasks, such as statistical tagging and manipulation of N-best lists and word lattices. This paper summarizes the functionality of the toolkit and discusses its design and implementation, highlighting ease of rapid prototyping, reusability, and combinability of tools.},
author = {Stolcke, Andreas},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Stolcke - 2002 - SRILM - An extensible language modeling toolkit.pdf:pdf},
journal = {Proceedings of the 7th International Conference on Spoken Language Processing},
pages = {901--904},
title = {{SRILM - An extensible language modeling toolkit}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.157.2429},
year = {2002}
}
@article{Uber2018,
author = {Uber, Release and Labs, A I},
file = {:Users/pablomaciasmunoz/Library/Application Support/Mendeley Desktop/Downloaded/Uber, Labs - 2018 - Pyro Documentation.pdf:pdf},
title = {{Pyro Documentation}},
year = {2018}
}
